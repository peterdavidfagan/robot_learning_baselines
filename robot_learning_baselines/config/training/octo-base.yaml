# parallel training
parallel_training: false

# checkpoint manager
checkpoint_dir: ${project.base_path}/.checkpoints/${wandb.experiment_name}/concept_learner
max_checkpoints: 2
save_interval: 50

# training hyperparameters
num_epochs: 50
batch_size: 32
momentum: 0.9

# learning rate scheduler
initial_lr: 1e-7
peak_lr: 3e-4
end_lr: 1e-5
weight_decay: 1e-1
max_grad_norm: 1.0
warmup_steps: 2000
warmup_epochs: 1
steps_per_epoch: 1000

