stacked_encoder_1d_block:
  _target_: multi_modal_transformers.attention_blocks.compressed_attention.StackedCompressedEncoder1DBlock
  num_blocks: 12
  encoder_1d_block:
    _target_: multi_modal_transformers.attention_blocks.compressed_attention.CompressedEncoder1DBlock
    
    layer_norm:
      _target_: flax.linen.LayerNorm
      epsilon: 1e-6
      reduction_axes: [1]
      feature_axes: [-1]
      dtype: ${config.architecture.multi_modal_transformer.dtype}
      param_dtype: ${config.architecture.multi_modal_transformer.param_dtype}
    
    dropout:
      _target_: flax.linen.Dropout
      rate:  ${config.architecture.multi_modal_transformer.dropout_rate}
    
    self_attention:
      _target_: multi_modal_transformers.attention_blocks.compressed_attention.CompressedMultiHeadDotProductAttention
      num_heads: 12
      qkv_features: ${config.architecture.multi_modal_transformer.token_embedding_dim}
      dropout_rate: ${config.architecture.multi_modal_transformer.attention_dropout_rate}
      decode: false
      kernel_init:
        _target_: flax.linen.initializers.xavier_uniform
      use_bias: true
      bias_init:
        _target_: flax.linen.initializers.normal
      dtype: ${config.architecture.multi_modal_transformer.dtype}
      param_dtype: ${config.architecture.multi_modal_transformer.param_dtype}
    
    mlp_block:
      _target_: multi_modal_transformers.attention_blocks.attention.MLPBlock
      dense:
        _target_: flax.linen.Dense
        features: 3072
        kernel_init:
          _target_: flax.linen.initializers.he_normal
        use_bias: true
        bias_init:
          _target_: flax.linen.initializers.normal
      
      activation:
        _partial_: true
        _target_: flax.linen.gelu
      
      norm:
        _target_: flax.linen.Dropout
        rate: ${config.architecture.multi_modal_transformer.dropout_rate}
      
      dense_out:
        _target_: flax.linen.Dense
        features: ${config.architecture.multi_modal_transformer.token_embedding_dim}
        kernel_init:
          _target_: flax.linen.initializers.he_normal
        use_bias: true
        bias_init:
          _target_: flax.linen.initializers.normal

