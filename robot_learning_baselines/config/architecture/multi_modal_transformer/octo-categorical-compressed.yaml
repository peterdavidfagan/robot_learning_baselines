# global architecture params
dtype: float32
param_dtype: float32
token_embedding_dim: 768 
dropout_rate: 0.1
attention_dropout_rate: 0.0

# describe the input sequence modalities and number of tokens
input_sequence: "[TaskDescriptionPrefix{16}] [Image{25};Readout{7}]*2"
tokens_per_task_description: 16
tokens_per_image: 25
tokens_per_readout: 7
num_observation_blocks: 2

# describe token compression strategy
token_compression_schedule:
  _target_: multi_modal_transformers.tokenizers.token_sequencer.ConstantCompressionSchedule
  token_sequence:  ${config.architecture.multi_modal_transformer.input_sequence}
  modality_compression_rate:
    prune:
      TaskDescriptionPrefix: 0
      Image: 2
      Readout: 0
    merge:
      TaskDescriptionPrefix: 0
      Image: 2
      Readout: 0
  start_layer_idx: 8

# action head prediction settings
forward_method: predict_action_logits
prediction_type: categorical

defaults:
  - tokenizers/text: t5_base
  - tokenizers/images: gato_resnet
  - tokenizers/readouts: octo
  - attention_blocks: compressed_decoder
  - action_heads: categorical

